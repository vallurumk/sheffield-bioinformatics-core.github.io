---
title: "Analysis of Single-Cell RNA-seq - Session 2"
author: "Niamh Errington"
date: '`r format(Sys.time(), "Last modified: %d %b %Y")`'
output:
  html_notebook:
    toc: yes
    toc_float: yes
    css: stylesheets/styles.css
  html_document:
    toc: yes
    df_print: paged
---
<img src="images/logo-sm.png" style="position:absolute;top:40px;right:10px;" width="200" />

# Introduction

In session 1, we read in our data and created a seurat object. We then performed some quality control, and subset the data according to the QC plots we generated. In this session, we are going to normalise the data, select the most variable features and scale,regressing out unwanted sources of variation. 

## Learning Objectives

* Build code to normalise data 

* Identify unwanted sources of variation in the data & find variable genes

* Execute SCTransform to transform data and regress out unwanted variation

* Build code to integrate data & form clusters

![](images/flowchart2.png)


# Normalisation 

Now that we have our high quality cells, there are still a few steps left before we can cluster cells. 

Firstly, we normalise the expression values. Then we identify highly variable genes. Next, data is scaled and unwanted effects regressed out. Then we integrate samples together, and finally, we do dimension reduction.


```{r}
#Re-load libraries
library(Seurat)
library(tidyverse)
```

```{r}
#Reload R objects if necessary 
filtered_data <- readRDS("Robjects/seurat_filtered.RDS")
```


# Sources of Variation

- Goal is to identify clusters that show interesting biological variation between cells.
- Differences in sequencing depth is common to bulk seq
- Cell cycle is often influential
- Can identify cell cycle status using a few key genes

We want to be able to check for potential sources of unwanted variation before we do our normalisation and regresssion of unwanted variation. One of the most common sources of unwanted variation is cell cycle. Before we can check for this, we need the counts to be comparable between cells, currently each cell has a different number for `nCount_RNA` (the number of UMI).

```{r}
summary(filtered_data$nCount_RNA)
```

We can use the `NormalizeData` function to use log normalisation to take the sequencing depth into account. `nCount_RNA` for each gene is divided by the total `nCount_RNA` for that cell, and then multiplied by the scale factor (default 10,000). This is natural-log transformed using log1p. 

```{r}
filtered_data <- NormalizeData(filtered_data)
```

We determine which phase of the cell cycle a cell is in, based on it's expression of phase markers. We've included the list we need here as a txt, but some other organisms can be found [here](https://github.com/hbc/tinyatlas/tree/master/cell_cycle), as well as a resource [here](https://hbctraining.github.io/scRNA-seq_online/lessons/cell_cycle_scoring.html) for finding cell markers for other organisms.

```{r}
cc_genes <- read.delim("regev_lab_cell_cycle_genes.txt")[,1]
s_genes <- cc_genes[1:43]
g2m_genes <- cc_genes[44:97]

seurat_phase <- CellCycleScoring(filtered_data, 
                                 g2m.features = g2m_genes, 
                                 s.features = s_genes)

# View cell cycle scores and phases assigned to cells                                 
View(seurat_phase@meta.data)  
```

Each cell is given a score, based on it's expression of the phase markers using the `CellCycleScoring()` function. We now have 3 new columns. The highest score between S.Score and G2M.Score determines the phase. If both columns are negative, then the phase is G1. A bar plot shows us how many cells are in each phase. 

```{r}
as_tibble(seurat_phase[[]]) %>% ggplot(aes(x = Phase, fill = Phase))+ geom_bar()
```

Find features that define clusters, using the `FindVariableFeatures` function. Seurat does this by calculating a normalised intensity for each gene, then selecting the top 'n' most variable features, in our case, the top 2000 genes. The samples contain PBMCs, so seeing immune-related genes in the top 20 is in line with what we would expect.

```{r}
# Identify the most variable genes
seurat_phase <- FindVariableFeatures(seurat_phase, 
                     selection.method = "vst",
                     nfeatures = 2500, #default
                     verbose = FALSE)

# Identify the top 20 most highly variable genes. We need the VariableFeatures function to pull the names
top20 <- head(VariableFeatures(seurat_phase), 20)

# The variablity can be accessed using the HVFInfo function
var.data <- as_tibble(HVFInfo(seurat_phase), rownames = "Gene") %>% mutate(Included = Gene %in% VariableFeatures(seurat_phase))

# Plot the variable features
VarPlot<- VariableFeaturePlot(seurat_phase)

LabelPoints(plot = VarPlot, points = top20, repel = TRUE,  xnudge = 0, ynudge = 0)
```

We're finally ready to see if cell cycle is a driving factor of variation, using PCA. After finding the most variable gene features (above), we scale the data to account for these highly variable genes. The `ScaleData` function will do this for us, such that the mean expression in each cell is 0, with a variance of 1. This ensures highly-expressed genes are not dominating, as we don't want the high expression values to be the only thing reflected in the highly variable genes. 

```{r}
# Scale the counts
seurat_phase <- ScaleData(seurat_phase)

# Perform PCA
seurat_phase <- RunPCA(seurat_phase)
```

Let's visualise the PCA. The plots for each phase look quite different, so we'll need to regress out cell cycle variation. 

```{r}
# Plot the PCA colored by cell cycle phase
DimPlot(seurat_phase, reduction = "pca",group.by = "Phase")
```


Mitochondrial genes can also affect clusters. 

```{r}
summary(seurat_phase$mito.ratio)
seurat_phase$mito.cat <- cut(seurat_phase$mito.ratio, breaks=c(-Inf,0.02036  , 0.03330 ,0.04558 ,Inf),labels=c("Low","Medium","Medium High","High"))

DimPlot(seurat_phase,
        reduction = "pca",
        group.by= "mito.cat")

```


# SCTransform

We decide to regress for mitochondrial ratio, number of UMI and cell-cycle status. First we split the object into a list of subsetted objects, where there is 1 for each sample. This step might take a while. 

SCTransform does the data normalisation, data scaling & finding of variable features. Sequencing depth is automatically regressed out, but it doesn't hurt to include nUMI in our list of variables to regress so we can follow.

```{r message=FALSE}
seurat_split <- SplitObject(seurat_phase, split.by = "SampleName")

for(i in 1:length(seurat_split)){
  
  seurat_split[[i]] <- SCTransform(seurat_split[[i]],vars.to.regress = c("mito.ratio","nUMI","S.Score","G2M.Score") )
}

```

# Integration

Batch effect has not been addressed. This is potentially something that could be addressed within the SCTransform step we just performed, but regressing out assumes that the 'batch effect' is the same for all cells. As this is not normally the case, the seurat team developed a method specifically for dealing with this issue - integration. If our ultimate goal is to compare cell-type expression between groups, we'll need to integrate the data. If you go back to look at older single cell papers, you'll probably see that they haven't done this step, but it is now recognised to be more important. It is optional, but recommended. 

There are 4 steps for integration: 

1. Select variable features for integration by taking the highly variable genes from each sample identified using SCTransform above, we can specify here that we want to use the 3000 most variable genes for integration.

2. Prepare the SCTransform object for integration

3. Identify 'anchors' between cells. These are mutual nearest neighbours across the data. For each cell, the closest neighbour is identified based on gene expression. If the neighbour's closest neighbour is the original cell, these will be marked as 'anchors' for the data.

4. Integrate the conditions / samples by using the anchors along with their corresponding scores to transform cell expression values. 

```{r}
# Select variable features for integration
integ_features <- SelectIntegrationFeatures(object.list = seurat_split, nfeatures = 3000)

# Prepare the SCTransform object for integration
seurat_split <- PrepSCTIntegration(object.list = seurat_split, anchor.features = integ_features)
```

```{r}
# Identify mutual nearest neighbours across datasets
integ_anchors <- FindIntegrationAnchors(object.list = seurat_split, 
                                        normalization.method = "SCT",
                                        anchor.features = integ_features)

# Integrate across samples
seurat_integrated <- IntegrateData(anchorset = integ_anchors,normalization.method = "SCT")
```


Now we can run an analysis on the integrated object.

```{r}
# Run PCA, UMAP & TSNE
seurat_integrated <- RunPCA(object = seurat_integrated)
seurat_integrated <- RunTSNE(object = seurat_integrated)
seurat_integrated <- RunUMAP(object = seurat_integrated, dims = 1:30, verbose = FALSE) #Theres quite a lot of output for this command, if we don't want that, we can use the verbose = FALSE
```

<div class="exercise">
**Exercise:** It's a good idea to check what these clusters look like. Make a plot to examine the new PCA and UMAP for the new integrated object. Split the plot so there is 1 for each sample group. Then make another for cell phase.
</div>

We might want to check the numbers as well. We expect the majority of cell type clusters to be present in both samples, however depending on the experiment we might expect condition specific cell types instead.

```{r}
# Extract identity and sample information from seurat object to determine the number of cells per cluster per sample
n_cells <- FetchData(seurat_integrated, 
                     vars = c("ident", "orig.ident")) %>%
        dplyr::count(ident, orig.ident) %>%
        tidyr::spread(ident, n)

# View table
View(n_cells)
```


# Determine the 'dimensionality'

An elbow plot is a way to help determine how many PCs we should look at to ensure the majority of variation in the data is captured. The elbow plot helps to visualise the standard deviation of each PC. The location of the 'elbow bend' provides us with a good guess for how many PCs we should include. Let's plot the top 30 dimensions.

```{r}
# Plot the elbow plot
ElbowPlot(object = seurat_integrated, ndims = 30)
```

When we interpret the elbow plot, we use the 'elbow' to determine the point at which an extra PC is bringing diminishing returns and is no longer adding a meaningful reduction in standard deviation. As in this example, the precise elbow is not always easy to spot. We can also look at dimensionality heatmaps to give us another view. These show the PCA weightings for the highest and lowest weighted genes, against the genes most influenced by the PC. We interpret them by looking for a clear structure. Once that structure is lost, we're probably no longer adding useful information. If we plot the first 10, where we can see each PC is still adding information, we can see what they look like when they're informative.


```{r}
DimHeatmap(seurat_integrated, dims = 1:10, cells = 100, balanced = TRUE)
DimHeatmap(seurat_integrated, dims = 10:22, cells = 100, balanced = TRUE)
```

We can look at the most variable genes driving the PCA:

```{r}
print(x = seurat_integrated[["pca"]], 
      dims = 1:5, 
      nfeatures = 5)
```

Next we will explore additional metrics, such as the number of UMIs and genes per cell, S-phase and G2M-phase markers, and mitochondrial gene expression by UMAP. Looking at the individual S and G2M scores can give us additional information to checking the phase as we did previously.

```{r}
FeaturePlot(seurat_integrated, 
            reduction = "umap", 
            features = c("nUMI", "nGene", "S.Score", "G2M.Score"),
            pt.size = 0.4, 
            order = TRUE,
            min.cutoff = 'q10',
            label = TRUE)

```

# Find clusters

We decided from our Elbow plot how many dimensions to use in our clustering approach. We're going to do this in 2 steps. The first command is going to construct a K-nearest neighbour (KNN) graph using the `FindNeightbors()` function. Part of the input here is based on the elbow plot, where we've decided to use the top 21 dimensions. The second step is to use the `FindClusters()` function, which performs the actual clustering. The resolution argument here sets the 'granularity' for downstream clustering. A higher value results in more clusters. Seurat recommends picking a value between 0.4-1.2 for single cell sets ~3K cells. 


```{r}
seurat_integrated <- FindNeighbors(seurat_integrated, dims = 1:21, verbose = FALSE)
seurat_integrated <- FindClusters(seurat_integrated, verbose = FALSE, resolution = 0.5)
```

We can use the `DimPlot` function again to plot our new clusters. 

```{r}
DimPlot(seurat_integrated, label = TRUE) + NoLegend()
```

Save the Seurat data as an R object again.

```{r}
saveRDS(seurat_integrated, file = "Robjects/seurat_integrated.RDS")
```



